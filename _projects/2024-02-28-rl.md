---
title: 'Model-Free Reinforcement Learning'
subtitle: 'Optimizing particle properties in cooling crystallization.'
date: 2024-02-28 00:00:00
description: Chemical Process Design
featured_image: '/images/projects/rl/4.jpg'
---

![](/images/projects/rl/4.jpg)

## Summary

In this project, I explored whether a complex, time-dependent chemical process—the unseeded batch cooling crystallization—can be optimized using **model-free deep reinforcement learning**. 
The process was formulated as a **Markov Decision Process** (Fig. 1), and a **Proximal Policy Optimization (PPO)** agent was trained to learn its control policy directly from simulated process data.

<center>
<figure>
<img src="/images/projects/rl/batch_crystallization.png" width="800">
<figcaption><b>Fig. 1:</b> Batch cooling crystallization diagram of paracetamol.</figcaption>
</figure>
</center>

The objective was to deliberately shape the particle size distribution and produce larger, more stable crystals.
The RL agent autonomously developed a control strategy that clearly outperformed classical benchmark profiles:
- **larger mean particle size** compared with human-designed and naïve cooling strategies
- **comparable yield**, despite stronger optimization toward particle size
- **robust and consistent control actions** across the entire process trajectory

[This work](https://www.techrxiv.org/users/744356/articles/716756-crystallization-process-design-by-model-free-deep-reinforcement-learning) demonstrates how modern reinforcement-learning methods can discover **optimal process pathways in complex, nonlinear systems** when a suitable simulation environment is available—opening new opportunities for data-driven process development and digital chemical engineering.

<div class="gallery" data-columns="3">
	<img src="/images/projects/rl/learning_curve.png">
    <img src="/images/projects/rl/ppo_trajectory.png">
    <img src="/images/projects/rl/comparison.png">
</div>